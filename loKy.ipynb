{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting lokyWARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "  Using cached loky-2.9.0-py2.py3-none-any.whl (67 kB)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: cloudpickle, loky\n",
      "Successfully installed cloudpickle-1.6.0 loky-2.9.0\n",
      "\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.1; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install loky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from loky import get_reusable_executor\n",
    "excutor = get_reusable_executor(max_workers=4)\n",
    "print(excutor.executor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "excutor = get_reusable_executor(max_workers=4)\n",
    "print(excutor.executor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "excutor = get_reusable_executor(max_workers=4)\n",
    "print(excutor.executor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1941407100496"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "excutor.submit(id, 42).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1634479992400"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "excutor.submit(id, 42).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1941407100496"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "excutor.submit(id, 42).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1634479992400"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "excutor.submit(id, 42).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "initialized\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "import multiprocessing as mp\n",
    "import loky\n",
    "from loky import get_reusable_executor\n",
    "\n",
    "# Store the initialization status in a global variable of a module.\n",
    "loky._INITIALIZER_STATUS = \"uninitialized\"\n",
    "\n",
    "\n",
    "def initializer(x):\n",
    "    print(\"[{}] init\".format(mp.current_process().name))\n",
    "    loky._INITIALIZER_STATUS = x\n",
    "\n",
    "\n",
    "def return_initializer_status(delay=0):\n",
    "    sleep(delay)\n",
    "\n",
    "    return getattr(loky, '_INITIALIZER_STATUS', 'uninitialized')\n",
    "\n",
    "\n",
    "executor = get_reusable_executor(\n",
    "    max_workers=2, initializer=initializer, initargs=('initialized',),\n",
    "    context=\"loky\", timeout=1000)\n",
    "\n",
    "assert loky._INITIALIZER_STATUS == \"uninitialized\"\n",
    "print(executor.submit(return_initializer_status).result())\n",
    "assert executor.submit(return_initializer_status).result() == 'initialized'\n",
    "\n",
    "# With reuse=True, the executor use the same initializer\n",
    "executor = get_reusable_executor(max_workers=4, reuse=True)\n",
    "for x in executor.map(return_initializer_status, [.5] * 4):\n",
    "    assert x == 'initialized'\n",
    "\n",
    "# With reuse='auto', the initializer is not used anymore as a new executor\n",
    "# is created.\n",
    "executor = get_reusable_executor(max_workers=4)\n",
    "for x in executor.map(return_initializer_status, [.1] * 4):\n",
    "    assert x == 'uninitialized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9280\n9280\n9280\nAll the jobs were run in a process different from main process\nAll the computation where run in a single `ProcessPoolExecutor` with worker pid=9280\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from loky import get_reusable_executor\n",
    "\n",
    "\n",
    "def func_async(i):\n",
    "    import os\n",
    "    pid = os.getpid()\n",
    "    return (2 * i, pid)\n",
    "\n",
    "\n",
    "def test_1():\n",
    "    executor = get_reusable_executor(max_workers=1)\n",
    "    return executor.submit(func_async, 1)\n",
    "\n",
    "\n",
    "def test_2():\n",
    "    executor = get_reusable_executor(max_workers=1)\n",
    "    return executor.submit(func_async, 2)\n",
    "\n",
    "\n",
    "def test_3():\n",
    "    executor = get_reusable_executor(max_workers=1)\n",
    "    return executor.submit(func_async, 3)\n",
    "\n",
    "\n",
    "f1 = test_1()\n",
    "f2 = test_2()\n",
    "f3 = test_3()\n",
    "\n",
    "main_pid = os.getpid()\n",
    "results = [f1.result(), f2.result(), f3.result()]\n",
    "\n",
    "pids = [pid for _, pid in results]\n",
    "\n",
    "for i, (val, pid) in enumerate(results):\n",
    "    assert val == 2 * (i + 1)\n",
    "    assert pid != main_pid\n",
    "    print(pid)\n",
    "print(\"All the jobs were run in a process different from main process\")\n",
    "\n",
    "assert len(set(pids)) == 1\n",
    "print(\"All the computation where run in a single `ProcessPoolExecutor` with \"\n",
    "      \"worker pid={}\".format(pids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "42\n",
      "With cloudpickle serialization: 0.118s\n",
      "With pickle serialization: 0.120s\n",
      "loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python39\\lib\\site-packages\\loky\\process_executor.py\", line 404, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"C:\\Python39\\lib\\multiprocessing\\queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'func_async' on <module '__main__' (built-in)>\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-16-85316087e36b>\", line 71, in <module>\n",
      "    executor.submit(func_async, 21, large_list).result()\n",
      "  File \"C:\\Python39\\lib\\concurrent\\futures\\_base.py\", line 440, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Python39\\lib\\concurrent\\futures\\_base.py\", line 389, in __get_result\n",
      "    raise self._exception\n",
      "loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "With default and wrapper: 0.340s\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from loky import set_loky_pickler\n",
    "from loky import get_reusable_executor\n",
    "from loky import wrap_non_picklable_objects\n",
    "\n",
    "###############################################################################\n",
    "# First, define functions which cannot be pickled with the standard ``pickle``\n",
    "# protocol. They cannot be serialized with ``pickle`` because they are defined\n",
    "# in the ``__main__`` module. They can however be serialized with\n",
    "# ``cloudpickle``.\n",
    "#\n",
    "\n",
    "\n",
    "def func_async(i, *args):\n",
    "    return 2 * i\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# With the default behavior, ``loky`` is to use ``cloudpickle`` to serialize\n",
    "# the objects that are sent to the workers.\n",
    "#\n",
    "\n",
    "executor = get_reusable_executor(max_workers=1)\n",
    "print(executor.submit(func_async, 21).result())\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# For most use-cases, using ``cloudpickle``` is efficient enough. However, this\n",
    "# solution can be very slow to serialize large python objects, such as dict or\n",
    "# list, compared to the standard ``pickle`` serialization.\n",
    "#\n",
    "\n",
    "# We have to pass an extra argument with a large list (or another large python\n",
    "# object).\n",
    "large_list = list(range(1000000))\n",
    "\n",
    "t_start = time.time()\n",
    "executor = get_reusable_executor(max_workers=1)\n",
    "executor.submit(func_async, 21, large_list).result()\n",
    "print(\"With cloudpickle serialization: {:.3f}s\".format(time.time() - t_start))\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# To mitigate this, it is possible to fully rely on ``pickle`` to serialize\n",
    "# all communications between the main process and the workers. This can be done\n",
    "# with an environment variable ``LOKY_PICKLER=pickle`` set before the\n",
    "# script is launched, or with the switch ``set_loky_pickler`` provided in the\n",
    "# ``loky`` API.\n",
    "#\n",
    "\n",
    "# Now set the `loky_pickler` to use the pickle serialization from stdlib. Here,\n",
    "# we do not pass the desired function ``call_function`` as it is not picklable\n",
    "# but it is replaced by ``id`` for demonstration purposes.\n",
    "set_loky_pickler('pickle')\n",
    "t_start = time.time()\n",
    "executor = get_reusable_executor(max_workers=1)\n",
    "executor.submit(id, large_list).result()\n",
    "print(\"With pickle serialization: {:.3f}s\".format(time.time() - t_start))\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# However, the function and objects defined in ``__main__`` are not\n",
    "# serializable anymore using ``pickle`` and it is not possible to call\n",
    "# ``func_async`` using this pickler.\n",
    "#\n",
    "\n",
    "try:\n",
    "    executor = get_reusable_executor(max_workers=1)\n",
    "    executor.submit(func_async, 21, large_list).result()\n",
    "except Exception:\n",
    "    traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# ``loky`` provides a wrapper function\n",
    "# :func:`wrap_non_picklable_objects` to wrap the non-picklable function and\n",
    "# indicate to the serialization process that this specific function should be\n",
    "# serialized using ``cloudpickle``. This changes the serialization behavior\n",
    "# only for this function and keeps using ``pickle`` for all other objects. The\n",
    "# drawback of this solution is that it modifies the object. This should not\n",
    "# cause many issues with functions but can have side effects with object\n",
    "# instances.\n",
    "#\n",
    "\n",
    "@wrap_non_picklable_objects\n",
    "def func_async_wrapped(i, *args):\n",
    "    return 2 * i\n",
    "\n",
    "\n",
    "t_start = time.time()\n",
    "executor = get_reusable_executor(max_workers=1)\n",
    "executor.submit(func_async_wrapped, 21, large_list).result()\n",
    "print(\"With default and wrapper: {:.3f}s\".format(time.time() - t_start))\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# The same wrapper can also be used for non-picklable classes. Note that the\n",
    "# side effects of :func:`wrap_non_picklable_objects` on objects can break magic\n",
    "# methods such as ``__add__`` and can mess up the ``isinstance`` and\n",
    "# ``issubclass`` functions. Some improvements will be considered if use-cases\n",
    "# are reported.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}